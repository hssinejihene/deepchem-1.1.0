{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks through the creation of multitask models on MUV. The goal is to demonstrate that multitask methods outperform singletask methods on MUV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%pdb off\n",
    "reload = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of dataset: ['mol_id' 'smiles' 'MUV-692' 'MUV-689' 'MUV-846' 'MUV-859' 'MUV-644'\n",
      " 'MUV-548' 'MUV-852' 'MUV-600' 'MUV-810' 'MUV-712' 'MUV-737' 'MUV-858'\n",
      " 'MUV-713' 'MUV-733' 'MUV-652' 'MUV-466' 'MUV-832']\n",
      "Number of examples in dataset: 93127\n"
     ]
    }
   ],
   "source": [
    "from deepchem.utils.save import load_from_disk\n",
    "from deepchem.datasets import Dataset\n",
    "\n",
    "dataset_file= \"../datasets/muv.csv.gz\"\n",
    "dataset = load_from_disk(dataset_file)\n",
    "print(\"Columns of dataset: %s\" % str(dataset.columns.values))\n",
    "print(\"Number of examples in dataset: %s\" % str(dataset.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize some compounds from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test0.png' /><img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test1.png' /><img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test10.png' /><img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test11.png' /><img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test2.png' /><img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test3.png' /><img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test4.png' /><img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test5.png' /><img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test6.png' /><img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test7.png' /><img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test8.png' /><img style='width: 140px; margin: 0px; float: left; border: 1px solid black;' src='test9.png' />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "from rdkit import Chem\n",
    "from deepchem.utils.visualization import mols_to_pngs\n",
    "from deepchem.utils.visualization import display_images\n",
    "\n",
    "num_to_display = 12\n",
    "molecules = []\n",
    "for _, data in islice(dataset.iterrows(), num_to_display):\n",
    "    molecules.append(Chem.MolFromSmiles(data[\"smiles\"]))\n",
    "display_images(mols_to_pngs(molecules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepchem.featurizers.fingerprints import CircularFingerprint\n",
    "\n",
    "featurizers = [CircularFingerprint(size=1024)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MUV_tasks = ['MUV-692', 'MUV-689', 'MUV-846', 'MUV-859', 'MUV-644',\n",
    "             'MUV-548', 'MUV-852', 'MUV-600', 'MUV-810', 'MUV-712',\n",
    "             'MUV-737', 'MUV-858', 'MUV-713', 'MUV-733', 'MUV-652',\n",
    "             'MUV-466', 'MUV-832']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from deepchem.featurizers.featurize import DataFeaturizer\n",
    "\n",
    "# The base_dir holds the results of all analysis\n",
    "base_dir = \"/scratch/users/rbharath/muv_multitask_analysis\"\n",
    "#Make directories to store the raw and featurized datasets.\n",
    "feature_dir = os.path.join(base_dir, \"features\")\n",
    "samples_dir = os.path.join(base_dir, \"samples\")\n",
    "\n",
    "featurizer = DataFeaturizer(tasks=MUV_tasks,\n",
    "                            smiles_field=\"smiles\",\n",
    "                            compound_featurizers=featurizers,\n",
    "                            verbosity=\"low\")\n",
    "\n",
    "# Setting reload=True directs the featurizer to use existing featurization on disk if such exists.\n",
    "featurized_samples = featurizer.featurize(dataset_file, feature_dir, samples_dir, shard_size=4096,\n",
    "                                          reload=reload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "splittype = \"scaffold\"\n",
    "train_dir = os.path.join(base_dir, \"train_dataset\")\n",
    "valid_dir = os.path.join(base_dir, \"valid_dataset\")\n",
    "test_dir = os.path.join(base_dir, \"test_dataset\")\n",
    "\n",
    "train_samples, valid_samples, test_samples = featurized_samples.train_valid_test_split(\n",
    "    splittype, train_dir, valid_dir, test_dir, log_every_n=1000, reload=reload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train dataset\n",
      "Creating valid dataset\n",
      "Creating test dataset\n"
     ]
    }
   ],
   "source": [
    "from deepchem.datasets import Dataset\n",
    "print(\"Creating train dataset\")\n",
    "verbosity = None\n",
    "train_dataset = Dataset(data_dir=train_dir, samples=train_samples, \n",
    "                        featurizers=featurizers, tasks=MUV_tasks,\n",
    "                        verbosity=verbosity, reload=reload)\n",
    "print(\"Creating valid dataset\")\n",
    "valid_dataset = Dataset(data_dir=valid_dir, samples=valid_samples, \n",
    "                        featurizers=featurizers, tasks=MUV_tasks,\n",
    "                        verbosity=verbosity, reload=reload)\n",
    "print(\"Creating test dataset\")\n",
    "test_dataset = Dataset(data_dir=test_dir, samples=test_samples, \n",
    "                       featurizers=featurizers, tasks=MUV_tasks,\n",
    "                       verbosity=verbosity, reload=reload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_transformers = []\n",
    "output_transformers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1 epochs\n",
      "Ending epoch 0: loss 0.00714142\n",
      "ys[0]\n",
      "[0.0 0.0 0.0 ..., 0.0 0.0 0.0]\n",
      "y_preds[0]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "Saving predictions to <open file '<fdopen>', mode 'w+b' at 0x7f280c626c00>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rbharath/deepchem/deepchem/metrics/__init__.py:151: UserWarning: Error calculating metric mean-roc_auc_score: unknown format is not supported\n",
      "  % (self.name, e))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model performance scores to <open file '<fdopen>', mode 'w+b' at 0x7f280c626b70>\n",
      "hyperparameters.compute\n",
      "valid_score\n",
      "nan\n",
      "hyperparameter_tuple\n",
      "('sgd', 1e-06, (1024,), 1, 'relu', (1000,), 50, 0.0, False, 'glorot_uniform', (1.0,), (0.1,), 2, 1, 17, 1000, False, (0.5,), 0.001, 0.9)\n",
      "Model 0/1, Metric mean-roc_auc_score, Validation set 0: nan\n",
      "\tbest_validation_score so far: -inf\n",
      "No models trained correctly.\n"
     ]
    }
   ],
   "source": [
    "from deepchem.hyperparameters import HyperparamOpt\n",
    "from deepchem.models.tensorflow_models import TensorflowModel\n",
    "from deepchem.models.tensorflow_models.fcnet import TensorflowMultiTaskClassifier\n",
    "from deepchem import metrics\n",
    "from deepchem.metrics import Metric\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "model_dir = os.path.join(base_dir, \"model\")\n",
    "\n",
    "MUV_task_types = {task: \"Classification\" for task in MUV_tasks}\n",
    "params_dict = {\"activation\": [\"relu\"],\n",
    "               \"momentum\": [.9],\n",
    "               \"batch_size\": [50],\n",
    "               \"init\": [\"glorot_uniform\"],\n",
    "               \"data_shape\": [train_dataset.get_data_shape()],\n",
    "               \"learning_rate\": [1e-3],\n",
    "               \"decay\": [1e-6],\n",
    "               \"nb_hidden\": [1000], \n",
    "               \"nb_epoch\": [1],\n",
    "               \"nesterov\": [False],\n",
    "               \"dropouts\": [(.5,)],\n",
    "               \"nb_layers\": [1],\n",
    "               \"batchnorm\": [False],\n",
    "               \"layer_sizes\": [(1000,)],\n",
    "               \"weight_init_stddevs\": [(.1,)],\n",
    "               \"bias_init_consts\": [(1.,)],\n",
    "               \"num_classes\": [2],\n",
    "               \"penalty\": [0.], \n",
    "               \"optimizer\": [\"sgd\"],\n",
    "               \"num_classification_tasks\": [len(MUV_task_types)]\n",
    "              } \n",
    "\n",
    "def model_builder(task_types, params_dict, logdir, verbosity=None):\n",
    "    return TensorflowModel(\n",
    "        task_types, params_dict, logdir, \n",
    "        tf_class=TensorflowMultiTaskClassifier,\n",
    "        verbosity=verbosity)\n",
    "\n",
    "metric = Metric(metrics.roc_auc_score, np.mean)\n",
    "optimizer = HyperparamOpt(model_builder, MUV_task_types, verbosity=\"low\")\n",
    "best_dnn, best_hyperparams, all_results = optimizer.hyperparam_search(\n",
    "    params_dict, train_dataset, valid_dataset, output_transformers, metric, logdir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
